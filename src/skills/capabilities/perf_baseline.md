---
id: perf_baseline
name: 性能基准
description: 建立性能基准，制定测试方法和性能指标
type: collection
acceptanceCriteria:
  - when: 性能基准建立完成
    then: 定义性能指标、测试方法、目标值
  - when: 输出性能报告
    then: 包含基准数据、测试方法、优化建议
---

# 性能基准

## 执行步骤

1. **明确性能需求**
   - 确定性能关注点
   - 定义性能指标
   - 设定目标值

2. **设计测试方案**
   - 选择测试工具
   - 设计测试场景
   - 准备测试数据

3. **执行基准测试**
   - 搭建测试环境
   - 运行测试脚本
   - 收集性能数据

4. **分析测试结果**
   - 整理性能数据
   - 识别性能瓶颈
   - 提出优化建议

5. **输出性能报告**
   - 按模板整理
   - 可视化数据（如可能）
   - 标注关键发现

## 检查清单

### 性能指标定义
- [ ] **响应时间**：P50/P95/P99 延迟目标？
- [ ] **吞吐量**：QPS/TPS 目标？
- [ ] **并发能力**：支持多少并发用户？
- [ ] **资源占用**：CPU/内存/磁盘限制？

### 测试场景设计
- [ ] **正常负载**：日常流量场景？
- [ ] **峰值负载**：高峰流量场景？
- [ ] **压力测试**：极限负载测试？
- [ ] **稳定性测试**：长时间运行测试？

### 测试环境
- [ ] **硬件配置**：CPU/内存/磁盘规格？
- [ ] **网络环境**：带宽、延迟？
- [ ] **软件版本**：语言、框架、依赖版本？
- [ ] **数据规模**：测试数据量？

### 测试工具
- [ ] **性能测试工具**：选择哪个工具？
- [ ] **监控工具**：如何监控资源？
- [ ] **数据采集**：如何收集性能数据？
- [ ] **可视化工具**：如何展示结果？

## 性能指标定义

### 响应时间（Latency）
- **P50（中位数）**：50% 请求的响应时间
- **P95**：95% 请求的响应时间
- **P99**：99% 请求的响应时间
- **Max**：最大响应时间

**目标示例**：
- P50 < 100ms
- P95 < 500ms
- P99 < 1000ms

### 吞吐量（Throughput）
- **QPS（Queries Per Second）**：每秒查询数
- **TPS（Transactions Per Second）**：每秒事务数
- **RPS（Requests Per Second）**：每秒请求数

**目标示例**：
- QPS > 1000
- TPS > 500

### 资源占用（Resource Usage）
- **CPU 使用率**：平均/峰值 CPU 使用率
- **内存占用**：平均/峰值内存占用
- **磁盘 I/O**：读写速度、IOPS
- **网络带宽**：入站/出站流量

**目标示例**：
- CPU 平均 < 60%，峰值 < 80%
- 内存 < 2GB
- 磁盘 I/O < 100 MB/s

### 并发能力（Concurrency）
- **并发用户数**：同时在线用户数
- **连接数**：TCP 连接数
- **线程/进程数**：系统资源占用

**目标示例**：
- 支持 10000 并发用户
- 最大连接数 5000

## 测试方法

### 基准测试（Baseline Test）
- **目的**：建立性能基线
- **负载**：正常负载（日常流量）
- **持续时间**：10-30 分钟
- **关注指标**：响应时间、吞吐量、资源占用

### 负载测试（Load Test）
- **目的**：验证系统在预期负载下表现
- **负载**：逐步增加到目标负载
- **持续时间**：30-60 分钟
- **关注指标**：系统稳定性、响应时间变化

### 压力测试（Stress Test）
- **目的**：找到系统性能极限
- **负载**：持续增加直到系统崩溃
- **持续时间**：直到找到瓶颈
- **关注指标**：最大吞吐量、失败点

### 稳定性测试（Soak Test）
- **目的**：验证长时间运行稳定性
- **负载**：持续正常负载
- **持续时间**：12-24 小时
- **关注指标**：内存泄漏、性能衰减

## 测试工具选择

### Web 应用
- **Apache Bench (ab)**：简单 HTTP 压测
- **wrk**：高性能 HTTP 压测
- **JMeter**：图形化性能测试工具
- **Gatling**：代码化性能测试

### API 测试
- **k6**：现代化负载测试
- **Locust**：Python 编写的负载测试
- **Artillery**：Node.js 性能测试

### 监控工具
- **htop/top**：系统资源监控
- **vmstat**：虚拟内存统计
- **iostat**：磁盘 I/O 统计
- **Prometheus + Grafana**：可视化监控

## 输出模板

```markdown
## 性能测试概要
**测试时间**：[时间]
**测试目的**：[建立基准/性能验证/压力测试]
**测试工具**：[工具名称及版本]

## 测试环境

### 硬件配置
- **CPU**：[型号、核心数]
- **内存**：[容量]
- **磁盘**：[类型、容量]
- **网络**：[带宽]

### 软件配置
- **操作系统**：[OS 版本]
- **运行时**：[Node/Python/Java 版本]
- **框架**：[框架及版本]
- **数据库**：[数据库及版本]

### 数据规模
- **数据量**：[记录数]
- **数据大小**：[总大小]
- **测试数据**：[测试数据说明]

## 性能指标

### 目标值
| 指标 | 目标值 | 优先级 |
|------|--------|--------|
| P50 延迟 | < 100ms | P0 |
| P95 延迟 | < 500ms | P0 |
| QPS | > 1000 | P1 |
| CPU 使用率 | < 60% | P1 |

## 测试场景

### 场景一：正常负载
- **并发用户数**：[数量]
- **请求速率**：[QPS]
- **持续时间**：[时间]
- **测试目的**：建立性能基线

### 场景二：峰值负载
- **并发用户数**：[数量]
- **请求速率**：[QPS]
- **持续时间**：[时间]
- **测试目的**：验证高峰表现

### 场景三：压力测试
- **并发用户数**：逐步增加
- **请求速率**：持续增加
- **持续时间**：直到系统崩溃
- **测试目的**：找到性能极限

## 测试结果

### 响应时间
| 场景 | P50 | P95 | P99 | Max | 目标 | 结果 |
|------|-----|-----|-----|-----|------|------|
| 正常负载 | 85ms | 420ms | 890ms | 1.2s | ✅ | 通过 |
| 峰值负载 | 120ms | 580ms | 1.1s | 2.5s | ⚠️ | P99 超标 |
| 压力测试 | 350ms | 1.5s | 3.2s | 5s | - | 瓶颈在 2000 QPS |

### 吞吐量
| 场景 | QPS | TPS | 目标 | 结果 |
|------|-----|-----|------|------|
| 正常负载 | 1200 | 600 | ✅ | 达标 |
| 峰值负载 | 1800 | 900 | ✅ | 达标 |
| 压力测试 | 2100 | 1050 | - | 极限值 |

### 资源占用
| 场景 | CPU 平均 | CPU 峰值 | 内存 | 磁盘 I/O | 结果 |
|------|----------|----------|------|----------|------|
| 正常负载 | 45% | 65% | 1.2GB | 20 MB/s | ✅ |
| 峰值负载 | 78% | 92% | 1.8GB | 45 MB/s | ⚠️ CPU 接近上限 |

### 错误率
| 场景 | 总请求数 | 成功数 | 失败数 | 错误率 |
|------|----------|--------|--------|--------|
| 正常负载 | 72000 | 72000 | 0 | 0% |
| 峰值负载 | 108000 | 107850 | 150 | 0.14% |

## 性能分析

### 瓶颈识别
1. **瓶颈点一**：[描述]
   - **现象**：[观察到的现象]
   - **原因**：[根本原因]
   - **证据**：[数据支持]

2. **瓶颈点二**：[描述]
   [同上结构]

### 性能热点
- **热点函数**：[函数名称、耗时占比]
- **慢查询**：[SQL 语句、执行时间]
- **资源瓶颈**：[CPU/内存/磁盘/网络]

## 优化建议

### 短期优化（Quick Wins）
1. **优化项一**
   - **问题**：[当前问题]
   - **建议**：[优化措施]
   - **预期收益**：[预期提升]
   - **工作量**：[时间估计]

2. **优化项二**
   [同上结构]

### 长期优化（Long-term）
1. **架构优化**：[架构层面改进]
2. **缓存策略**：[缓存优化建议]
3. **数据库优化**：[数据库优化方向]

## 测试脚本

### 基准测试脚本
\`\`\`bash
# 使用 wrk 进行基准测试
wrk -t 4 -c 100 -d 30s --latency http://localhost:3000/api/test
\`\`\`

### 压力测试脚本
\`\`\`bash
# 使用 k6 进行压力测试
k6 run --vus 100 --duration 30s performance-test.js
\`\`\`

### 监控脚本
\`\`\`bash
# 监控系统资源
while true; do
  echo "$(date) - CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')%"
  sleep 5
done
\`\`\`

## 性能数据可视化

### 响应时间分布图
[文字描述或ASCII图]
\`\`\`
P50: ████████░░ 85ms
P95: ████████████████░░ 420ms
P99: ████████████████████░ 890ms
\`\`\`

### 吞吐量趋势图
[描述吞吐量随并发数变化的趋势]

## 结论与建议

### 测试结论
- ✅ 正常负载下性能达标
- ⚠️ 峰值负载下 P99 延迟偏高
- ❌ CPU 在高负载下接近上限

### 优先优化项
1. [优化项1] - 优先级 P0
2. [优化项2] - 优先级 P1

### 后续计划
- [ ] 实施优化措施
- [ ] 重新进行性能测试
- [ ] 建立持续性能监控
```

## 验证规则

### 完整性检查
- 性能指标已定义
- 测试场景完整（至少包含基准测试）
- 测试环境信息齐全
- 测试结果数据完整

### 准确性检查
- 测试数据真实可信
- 性能指标计算正确
- 瓶颈分析有数据支持
- 优化建议切实可行

### 可复现性检查
- 测试脚本可执行
- 测试环境可重建
- 测试步骤明确
- 结果可验证

### 完成标准
- 性能基准已建立
- 瓶颈已识别
- 优化建议已提出
- 性能报告已输出
- 用户对结果已确认
